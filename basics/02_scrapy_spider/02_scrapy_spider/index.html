



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
        <meta name="author" content="jusk9527">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.1">
    
    
      
        <title>Scrapy 源码 Spider - Let's Scrapy!</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.30686662.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="black" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../.." title="Let's Scrapy!" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Let's Scrapy!
            </span>
            <span class="md-header-nav__topic">
              
                Scrapy 源码 Spider
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/jusk9527/LetsScrapy/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    LetsScrapy
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../.." title="Let's Scrapy!" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Let's Scrapy!
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/jusk9527/LetsScrapy/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    LetsScrapy
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="简介" class="md-nav__link">
      简介
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Scrapy 基础
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Scrapy 基础
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../11_scrapy_index/11_scrapy_index/" title="Scrapy 简单介绍" class="md-nav__link">
      Scrapy 简单介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../00_scrapy_setting/00_scrapy_setting/" title="Scrapy 源码 settings" class="md-nav__link">
      Scrapy 源码 settings
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../01_scrapy_request_response/01_scrapy_request_response/" title="Scrapy 源码 request、response" class="md-nav__link">
      Scrapy 源码 request、response
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Scrapy 源码 Spider
      </label>
    
    <a href="./" title="Scrapy 源码 Spider" class="md-nav__link md-nav__link--active">
      Scrapy 源码 Spider
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="前言" class="md-nav__link">
    前言
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="源码参考" class="md-nav__link">
    源码参考
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="参数解释" class="md-nav__link">
    参数解释
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../03_scrapy_crawlspiders/03_scrapy_crawlspiders/" title="Scrapy 源码 CrawlSpider" class="md-nav__link">
      Scrapy 源码 CrawlSpider
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04_scrapy_middlewares/04_scrapy_middlewares/" title="Scrapy 源码 Middewares" class="md-nav__link">
      Scrapy 源码 Middewares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05_scrapy_piplines/05_scrapy_piplines/" title="Scrapy 源码 pipelines" class="md-nav__link">
      Scrapy 源码 pipelines
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06_scrapy_log/06_scrapy_log/" title="Scrapy 源码 log" class="md-nav__link">
      Scrapy 源码 log
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07_scrapy_redis/07_scrapy_redis/" title="Scrapy 源码 scrapy-redis" class="md-nav__link">
      Scrapy 源码 scrapy-redis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08_scrapy_scrapyd/08_scrapy_scrapyd/" title="Scrapy scrapyd" class="md-nav__link">
      Scrapy scrapyd
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09_python_scrapyd_api/09_python_scrapyd_api/" title="Scrapy scrapyd-api" class="md-nav__link">
      Scrapy scrapyd-api
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10_scrapy_splash/10_scrapy_splash/" title="Scrapy splash" class="md-nav__link">
      Scrapy splash
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12_scrapy_实战项目/12_scrapy_实战项目/" title="Scrapy 实战项目" class="md-nav__link">
      Scrapy 实战项目
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="前言" class="md-nav__link">
    前言
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="源码参考" class="md-nav__link">
    源码参考
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="参数解释" class="md-nav__link">
    参数解释
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jusk9527/LetsScrapy/edit/master/docs/basics/02_scrapy_spider/02_scrapy_spider.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                  <h1>Scrapy 源码 Spider</h1>
                
                <h2 id="_1">前言<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p>class scrapy.Spider是最基本的类，所有编写的爬虫必须继承这个类。</p>
<h2 id="_2">源码参考<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="c1"># 所有爬虫的基类，用户定义的爬虫必须从这个类继承</span>
<span class="k">class</span> <span class="n">Spider</span>(<span class="n">object_ref</span>):
    <span class="s">&quot;&quot;&quot;Base class for scrapy spiders. All spiders must inherit from this</span>
<span class="s">    class.</span>
<span class="s">    &quot;&quot;&quot;</span>

    <span class="c1"># 定义spider名字的字符串(string) ,spider的名字定义了Scrapy如何定位(并初始化)spider,所以其必须是唯一的</span>
    <span class="c1"># name是spider最重要的属性，而且是必须的</span>
    <span class="c1"># 一般做法是以该网站(domain)(加或不加 后缀 )来命名spider。 例如，如果spider爬取 mywebsite.com ，该spider通常会被命名为 mywebsite</span>
    <span class="nb">name</span> = <span class="n">None</span>
    <span class="n">custom_settings</span> = <span class="n">None</span>


    <span class="c1">#初始化，提取爬虫名字，start_ruls</span>
    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>, <span class="nb">name</span>=<span class="n">None</span>, **<span class="n">kwargs</span>):
        <span class="k">if</span> <span class="nb">name</span> <span class="k">is</span> <span class="nb">not</span> <span class="n">None:</span>
            <span class="k">self</span>.<span class="nb">name</span> = <span class="nb">name</span>

        <span class="c1"># 如果爬虫没有名字，中断后续操作则报错</span>
        <span class="n">elif</span> <span class="nb">not</span> <span class="n">getattr</span>(<span class="k">self</span>, <span class="s">&#39;name&#39;</span>, <span class="n">None</span>):
            <span class="n">raise</span> <span class="n">ValueError</span>(<span class="s">&quot;%s must have a name&quot;</span> % <span class="n">type</span>(<span class="k">self</span>).<span class="n">__name__</span>)

        <span class="c1"># python 对象或类型通过内置成员__dict__来存储成员信息</span>
        <span class="k">self</span>.<span class="n">__dict__</span>.<span class="n">update</span>(<span class="n">kwargs</span>)

         <span class="c1">#URL列表。当没有指定的URL时，spider将从该列表中开始进行爬取。 因此，第一个被获取到的页面的URL将是该列表之一。 后续的URL将会从获取到的数据中提取。</span>
        <span class="k">if</span> <span class="nb">not</span> <span class="n">hasattr</span>(<span class="k">self</span>, <span class="s">&#39;start_urls&#39;</span>):
            <span class="k">self</span>.<span class="n">start_urls</span> = []

    <span class="c1"># 打印Scrapy执行后的log信息,是非常重要的</span>
    <span class="n">def</span> <span class="nb">log</span>(<span class="k">self</span>, <span class="n">message</span>, <span class="n">level</span>=<span class="n">logging</span>.<span class="n">DEBUG</span>, **<span class="n">kw</span>):
        <span class="nb">pass</span>




    <span class="c1">#该方法将读取start_urls内的地址，并为每一个地址生成一个Request对象，交给Scrapy下载并返回Response</span>
    <span class="c1">#该方法仅调用一次</span>
    <span class="n">def</span> <span class="n">start_requests</span>(<span class="k">self</span>):
        <span class="k">for</span> <span class="n">url</span> <span class="n">in</span> <span class="k">self</span>.<span class="n">start_urls:</span>
            <span class="n">yield</span> <span class="n">Request</span>(<span class="n">url</span>, <span class="n">dont_filter</span>=<span class="nb">True</span>)


    <span class="c1">#start_requests()中调用，实际生成Request的函数。</span>
    <span class="c1">#Request对象默认的回调函数为parse()，提交的方式为get</span>
    <span class="n">def</span> <span class="n">make_requests_from_url</span>(<span class="k">self</span>, <span class="n">url</span>):
        <span class="k">return</span> <span class="n">Request</span>(<span class="n">url</span>, <span class="n">dont_filter</span>=<span class="nb">True</span>)


    <span class="c1">#默认的Request对象回调函数，处理返回的response。</span>
    <span class="c1">#生成Item或者Request对象。用户必须实现这个类</span>
    <span class="n">def</span> <span class="n">parse</span>(<span class="k">self</span>, <span class="n">response</span>):
        <span class="n">raise</span> <span class="n">NotImplementedError</span>(<span class="s">&#39;{}.parse callback is not defined&#39;</span>.<span class="n">format</span>(<span class="k">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>))
</code></pre></div>
</td></tr></table>

<hr />
<p>主要逻辑</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">__init__</span><span class="p">()</span> <span class="p">:</span> <span class="err">初始化爬虫名字和</span><span class="n">start_urls列表</span>

<span class="n">start_requests</span><span class="p">()</span> <span class="err">调用</span><span class="n">make_requests_from</span> <span class="n">url</span><span class="p">():</span><span class="err">生成</span><span class="n">Requests对象交给Scrapy下载并返回response</span>

<span class="n">parse</span><span class="p">()</span> <span class="p">:</span> <span class="err">解析</span><span class="n">response</span><span class="err">，并返回</span><span class="n">Item或Requests</span><span class="err">（需指定回调函数）。</span><span class="n">Item传给Item</span> <span class="n">pipline持久化</span> <span class="err">，</span> <span class="err">而</span><span class="n">Requests交由Scrapy下载</span><span class="err">，并由指定的回调函数处理（默认</span><span class="n">parse</span><span class="p">())</span><span class="err">，一直进行循环，直到处理完所有的数据为止。</span>
</code></pre></div>
</td></tr></table>

<hr />
<h2 id="_3">参数解释<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>name</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="err">必须定义，爬虫的名称，字符串类型，这个名称标识这个爬虫，所以不能重复</span>
</code></pre></div>
</td></tr></table>

<p>start_urls</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="err">list类型，开始爬虫的URL列表(一个或者多个)，可以不用定义，然后用start_request()函数代替，去循环列表中的url去request</span>
</code></pre></div>
</td></tr></table>

<p>custom_settings</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="err">字典类型，可以设置setting中的值。针对不同的爬虫设置不同的值，因为settings文件只有一个</span>
</code></pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="err">custom_settings = {</span>
<span class="err">        &#39;ROBOTSTXT_OBEY&#39; : False,</span>
<span class="err">        &#39;DOWNLOAD_DELAY&#39; : 5</span>
<span class="err">    }</span>
</code></pre></div>
</td></tr></table>

<p>小技巧：设置setting值的优先级
1. 命令行选项
2. custom_settings
3. setting.py文件
4. 全局默认</p>
<hr />
<p>思考点
1. 为什么我们继承需要实现parse方法，有不实现的方法吗？
2. 很多时候需要登录怎么继承重写方法
3. 如果我们注释了setting中的某些参数，但是在custom_setting中却设置了有用吗，比如中间件
4. </p>
<p>回答</p>
<ol>
<li>这里我们可以重写start_requests()方法</li>
</ol>
<p>这里我们举个登录github的例子</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">GithubSpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;github_login&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;github.com&quot;</span><span class="p">]</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/login&#39;</span>

    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">url</span><span class="p">]</span>

    <span class="n">post_headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Accept&quot;</span><span class="p">:</span> <span class="s2">&quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Accept-Encoding&quot;</span><span class="p">:</span> <span class="s2">&quot;gzip, deflate&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Accept-Language&quot;</span><span class="p">:</span> <span class="s2">&quot;zh-CN,zh;q=0.8,en;q=0.6&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Cache-Control&quot;</span><span class="p">:</span> <span class="s2">&quot;no-cache&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Connection&quot;</span><span class="p">:</span> <span class="s2">&quot;keep-alive&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Content-Type&quot;</span><span class="p">:</span> <span class="s2">&quot;application/x-www-form-urlencoded&quot;</span><span class="p">,</span>
        <span class="s2">&quot;User-Agent&quot;</span><span class="p">:</span> <span class="s2">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.75 Safari/537.36&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Referer&quot;</span><span class="p">:</span> <span class="s2">&quot;https://github.com/&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">Request</span><span class="p">(</span><span class="s2">&quot;https://github.com/login&quot;</span><span class="p">,</span>
                        <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cookiejar&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">post_login</span><span class="p">)]</span>

    <span class="c1"># FormRequeset</span>
    <span class="k">def</span> <span class="nf">post_login</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># 先去拿隐藏的表单参数authenticity_token</span>
        <span class="n">authenticity_token</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span>
            <span class="s1">&#39;//input[@name=&quot;authenticity_token&quot;]/@value&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;authenticity_token=&#39;</span> <span class="o">+</span> <span class="n">authenticity_token</span><span class="p">)</span>

        <span class="c1"># FormRequeset.from_response是Scrapy提供的一个函数, 用于post表单</span>
        <span class="c1"># 登陆成功后, 会调用after_login回调函数，如果url跟Request页面的一样就省略掉</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">FormRequest</span><span class="o">.</span><span class="n">from_response</span><span class="p">(</span><span class="n">response</span><span class="p">,</span>
                                          <span class="n">url</span><span class="o">=</span><span class="s1">&#39;https://github.com/session&#39;</span><span class="p">,</span>
                                          <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cookiejar&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;cookiejar&#39;</span><span class="p">]},</span>
                                          <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">post_headers</span><span class="p">,</span>  <span class="c1"># 注意此处的headers</span>
                                          <span class="n">formdata</span><span class="o">=</span><span class="p">{</span>
                                              <span class="s1">&#39;utf8&#39;</span><span class="p">:</span> <span class="s1">&#39;✓&#39;</span><span class="p">,</span>
                                              <span class="s1">&#39;login&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                                              <span class="s1">&#39;password&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                                              <span class="s1">&#39;authenticity_token&#39;</span><span class="p">:</span> <span class="n">authenticity_token</span>
                                          <span class="p">},</span>
                                          <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">after_login</span><span class="p">,</span>
                                          <span class="n">dont_filter</span><span class="o">=</span><span class="kc">True</span>
                                          <span class="p">)]</span>




    <span class="k">def</span> <span class="nf">after_login</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># 登录之后，开始进入我要爬取的私信页面</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
            <span class="c1"># 因为我们上面定义了Rule，所以只需要简单的生成初始爬取Request即可</span>
            <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cookiejar&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;cookiejar&#39;</span><span class="p">]})</span>
</code></pre></div>
</td></tr></table>

<p>这是一个标准的登录模板具体步骤就是
- 先访问登录页面
- 然后表单提交
- 正常页面业务逻辑书写</p>
<p>3.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="err">一般在一个项目中有多个爬虫的时候我们习惯把公共的放在</span><span class="n">setting中</span><span class="err">，每个爬虫私有的就放在</span><span class="n">custom_settings中</span>

<span class="err">比如中间件的问题，有的需要代理，而有的不需要，那怎么办呢</span>

<span class="n">custom_settings</span> <span class="o">=</span> <span class="err">{</span>

    <span class="ss">&quot;DOWNLOADER_MIDDLEWARES&quot;</span> <span class="p">:</span> <span class="err">{</span>
        <span class="s1">&#39;a.middlewares.ProxyMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>

    <span class="err">}</span>
<span class="err">}</span>
</code></pre></div>
</td></tr></table>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../01_scrapy_request_response/01_scrapy_request_response/" title="Scrapy 源码 request、response" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Scrapy 源码 request、response
              </span>
            </div>
          </a>
        
        
          <a href="../../03_scrapy_crawlspiders/03_scrapy_crawlspiders/" title="Scrapy 源码 CrawlSpider" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Scrapy 源码 CrawlSpider
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 - 2020 PegasusWang
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/jusk9527" class="md-footer-social__link fa fa-github"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.c648116f.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>